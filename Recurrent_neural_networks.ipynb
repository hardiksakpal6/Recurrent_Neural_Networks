{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3wJQdDuHWOD"
      },
      "source": [
        "# Project: Recurrent Neural Networks\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "    Welcome to Project: Recurrent Neural Networks!<br>\n",
        "    <br>\n",
        "    This project works with a basic RNN architecture for text generation, namely Sequence to Seqeuence Models. The name points out that these models take a sequence as input and return another sequence as output.<br>\n",
        "    <br>\n",
        "    Sequence to Vector Models are similar, but return only a single output in the final time step. The latter architecture is, for example, suitable for sequence classification.\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPcLTZl2HWOP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t6oFYMSHpDd",
        "outputId": "8a90e32e-4080-455b-d2a7-95562a176b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsbO4vz1HWOR"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Read the text files <font face='courier'>hamlet_1.txt</font>, <font face='courier'>hamlet_2.txt</font> and <font face='courier'>hamlet_3.txt</font>.<br>\n",
        "    <br>\n",
        "    Store their content in variables <font face='courier'>hamlet_1_text</font>, <font face='courier'>hamlet_2_text</font> and <font face='courier'>hamlet_3_text</font>, respectively.<br>\n",
        "    <br>\n",
        "    Be aware that all files are UTF-8 encoded. Maybe you find <a href='https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files'>this link</a> helpful.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tF4kky9qHWOS"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/FPDS/project_3/hamlet_1.txt', encoding= 'utf-8') as f:\n",
        "    hamlet_1_text= f.read()\n",
        "with open('/content/drive/MyDrive/FPDS/project_3/hamlet_2.txt', encoding= 'utf-8') as f:\n",
        "    hamlet_2_text= f.read()\n",
        "with open('/content/drive/MyDrive/FPDS/project_3/hamlet_3.txt', encoding= 'utf-8') as f:\n",
        "    hamlet_3_text= f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZAPKV-7HWOS"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Print the first 325 characters of <font face='courier'>hamlet_1_text</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzAgfbDfHWOT",
        "outputId": "2062e956-4662-4b38-d436-b76286858d33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(hamlet_1_text[:325])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0cwR7uYHWOV"
      },
      "source": [
        "**Checkpoint:** You should see the following output:\n",
        "\n",
        "```\n",
        "The Tragedie of Hamlet\n",
        "\n",
        "Actus Primus. Scoena Prima.\n",
        "\n",
        "Enter Barnardo and Francisco two Centinels.\n",
        "\n",
        " Barnardo. Who's there?\n",
        "Fran. Nay answer me: Stand & vnfold\n",
        "your selfe\n",
        "\n",
        " Bar. Long liue the King\n",
        "\n",
        " Fran. Barnardo?\n",
        "Bar. He\n",
        "\n",
        " Fran. You come most carefully vpon your houre\n",
        "\n",
        " Bar. 'Tis now strook twelue, get thee to bed Francisco\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MdvCFZBHWOX"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Instantiate an object <font face='courier'>tokenizer</font> of type <font face='courier'>tf.keras.preprocessing.text.Tokenzier</font>.<br>\n",
        "    <br>\n",
        "    Submit the argument <font face='courier'>char_level=True</font> to the constructor.<br>\n",
        "    <br>\n",
        "    Helpful information can be found <a href='https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer'>here</a>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cLBaPLiHWOZ"
      },
      "outputs": [],
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzmKagceHWOb"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    The object <font face='courier'>tokenizer</font> will ultimately be used to encode the strings <font face='courier'>hamlet_1_text</font>, <font face='courier'>hamlet_2_text</font> and <font face='courier'>hamlet_3_text</font> as integer sequences in which each single number represents a specific character.<br>\n",
        "    <br>\n",
        "    Call the method <font face='courier'>fit_on_texts</font> of <font face='courier'>tokenizer</font>.<br>\n",
        "    <br>\n",
        "    In doing so, pass a list that contains exactly the strings <font face='courier'>hamlet_1_text</font>, <font face='courier'>hamlet_2_text</font> and <font face='courier'>hamlet_3_text</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPAjM2iZHWOd"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts([hamlet_1_text,hamlet_2_text,hamlet_3_text])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-4azdklHWOe"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    The above call creates a vocabulary in <font face='courier'>tokenizer</font>. This vocabulary assigns a positive integer to each unique character in the texts that were passed to the <font face='courier'>fit_on_texts</font> method.<br>\n",
        "    <br>\n",
        "    Display the attribute <font face='courier'>word_index</font> of <font face='courier'>tokenizer</font> which contains the created vocabulary.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ofM3mrWsHWOe",
        "outputId": "00bcd345-75f7-4d7a-cdb5-45cf25268cd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{' ': 1, 'e': 2, 't': 3, 'o': 4, 'a': 5, 'h': 6, 'i': 7, 'n': 8, 's': 9, 'r': 10, 'l': 11, '\\n': 12, 'u': 13, 'd': 14, 'm': 15, 'y': 16, ',': 17, 'w': 18, 'f': 19, 'c': 20, 'g': 21, '.': 22, 'p': 23, 'b': 24, 'k': 25, \"'\": 26, ':': 27, 'v': 28, '?': 29, ';': 30, 'q': 31, 'x': 32, '-': 33, 'z': 34, '(': 35, ')': 36, '&': 37, '!': 38, '[': 39, ']': 40, '1': 41, 'j': 42}\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziY3wcbfHWOh"
      },
      "source": [
        "**Checkpoint:** You should have got the following output:\n",
        "\n",
        "```\n",
        "{' ': 1, 'e': 2, 't': 3, 'o': 4, 'a': 5, 'h': 6, 'i': 7, 'n': 8, 's': 9, 'r': 10, 'l': 11, '\\n': 12, 'u': 13, 'd': 14, 'm': 15, 'y': 16, ',': 17, 'w': 18, 'f': 19, 'c': 20, 'g': 21, '.': 22, 'p': 23, 'b': 24, 'k': 25, \"'\": 26, ':': 27, 'v': 28, '?': 29, ';': 30, 'q': 31, 'x': 32, '-': 33, 'z': 34, '(': 35, ')': 36, '&': 37, '!': 38, '[': 39, ']': 40, '1': 41, 'j': 42}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_QtiOCRHWOh"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Compute the length of the vocabulary, store it in the variable <font face='courier'>max_id</font> and display this variable.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYbix2I6HWOi",
        "outputId": "b45fd158-8bce-4054-8d52-5724184351cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42\n"
          ]
        }
      ],
      "source": [
        "max_id = len(tokenizer.word_index)\n",
        "print(max_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zMPQwnVHWOi"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Now, use the method <font face='courier'>texts_to_sequences</font> of <font face='courier'>tokenzier</font> to encode <font face='courier'>hamlet_1_text</font>, <font face='courier'>hamlet_2_text</font> and <font face='courier'>hamlet_3_text</font>.<br>\n",
        "    <br>\n",
        "    Store the respective coded strings in <font face='courier'>hamlet_1_encoded</font>, <font face='courier'>hamlet_2_encoded</font> and <font face='courier'>hamlet_3_encoded</font>.<br>\n",
        "    <br>\n",
        "    Convert all three lists to the format <font face='courier'>numpy.array</font> and subtract <font face='courier'>1</font> from all entries so that all values range between <font face='courier'>0</font> and <font face='courier'>max_id - 1</font> afterwards.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4ta5Cr3HWOi"
      },
      "outputs": [],
      "source": [
        "hamlet_1_encoded, hamlet_2_encoded, hamlet_3_encoded= tokenizer.texts_to_sequences([hamlet_1_text, hamlet_2_text, hamlet_3_text])\n",
        "hamlet_1_encoded= np.asarray(hamlet_1_encoded)- 1\n",
        "hamlet_2_encoded= np.asarray(hamlet_2_encoded)- 1\n",
        "hamlet_3_encoded= np.asarray(hamlet_3_encoded)- 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kZD8QvoHWOj"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Display the first <font face='courier'>325</font> entries of <font face='courier'>hamlet_1_encoded</font>.\n",
        "    <a href=''></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOkagLLfHWOj",
        "outputId": "dff87184-5caa-4710-c959-acb3e091cc05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2  5  1  0  2  9  4 20  1 13  6  1  0  3 18  0  5  4 14 10  1  2 11 11\n",
            "  4 19  2 12  8  0 22  9  6 14 12  8 21  0  8 19  3  1  7  4  0 22  9  6\n",
            " 14  4 21 11 11  1  7  2  1  9  0 23  4  9  7  4  9 13  3  0  4  7 13  0\n",
            " 18  9  4  7 19  6  8 19  3  0  2 17  3  0 19  1  7  2  6  7  1 10  8 21\n",
            " 11 11  0 23  4  9  7  4  9 13  3 21  0 17  5  3 25  8  0  2  5  1  9  1\n",
            " 28 11 18  9  4  7 21  0  7  4 15  0  4  7  8 17  1  9  0 14  1 26  0  8\n",
            "  2  4  7 13  0 36  0 27  7 18  3 10 13 11 15  3 12  9  0  8  1 10 18  1\n",
            " 11 11  0 23  4  9 21  0 10  3  7 20  0 10  6 12  1  0  2  5  1  0 24  6\n",
            "  7 20 11 11  0 18  9  4  7 21  0 23  4  9  7  4  9 13  3 28 11 23  4  9\n",
            " 21  0  5  1 11 11  0 18  9  4  7 21  0 15  3 12  0 19  3 14  1  0 14  3\n",
            "  8  2  0 19  4  9  1 18 12 10 10 15  0 27 22  3  7  0 15  3 12  9  0  5\n",
            "  3 12  9  1 11 11  0 23  4  9 21  0 25  2  6  8  0  7  3 17  0  8  2  9\n",
            "  3  3 24  0  2 17  1 10 12  1 16  0 20  1  2  0  2  5  1  1  0  2  3  0\n",
            " 23  1 13  0 18  9  4  7 19  6  8 19  3]\n"
          ]
        }
      ],
      "source": [
        "print(hamlet_1_encoded[:325])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LGGj0cnHWOj"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Checkpoint:** Your output should be as follows:\n",
        "\n",
        "```\n",
        "[ 2  5  1  0  2  9  4 20  1 13  6  1  0  3 18  0  5  4 14 10  1  2 11 11\n",
        "  4 19  2 12  8  0 22  9  6 14 12  8 21  0  8 19  3  1  7  4  0 22  9  6\n",
        " 14  4 21 11 11  1  7  2  1  9  0 23  4  9  7  4  9 13  3  0  4  7 13  0\n",
        " 18  9  4  7 19  6  8 19  3  0  2 17  3  0 19  1  7  2  6  7  1 10  8 21\n",
        " 11 11  0 23  4  9  7  4  9 13  3 21  0 17  5  3 25  8  0  2  5  1  9  1\n",
        " 28 11 18  9  4  7 21  0  7  4 15  0  4  7  8 17  1  9  0 14  1 26  0  8\n",
        "  2  4  7 13  0 36  0 27  7 18  3 10 13 11 15  3 12  9  0  8  1 10 18  1\n",
        " 11 11  0 23  4  9 21  0 10  3  7 20  0 10  6 12  1  0  2  5  1  0 24  6\n",
        "  7 20 11 11  0 18  9  4  7 21  0 23  4  9  7  4  9 13  3 28 11 23  4  9\n",
        " 21  0  5  1 11 11  0 18  9  4  7 21  0 15  3 12  0 19  3 14  1  0 14  3\n",
        "  8  2  0 19  4  9  1 18 12 10 10 15  0 27 22  3  7  0 15  3 12  9  0  5\n",
        "  3 12  9  1 11 11  0 23  4  9 21  0 25  2  6  8  0  7  3 17  0  8  2  9\n",
        "  3  3 24  0  2 17  1 10 12  1 16  0 20  1  2  0  2  5  1  1  0  2  3  0\n",
        " 23  1 13  0 18  9  4  7 19  6  8 19  3]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJkRSX95HWOk"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    The original texts can be recovered via the method <font face='courier'>sequences_to_texts</font> of <font face='courier'>tokenizer</font>.<br>\n",
        "    <br>\n",
        "    Texts recovered in this way are all lower case and each original character is followed by a blank space.<br>\n",
        "    <br>\n",
        "    Apply <font face='courier'>sequences_to_texts</font> to <font face='courier'>hamlet_1_encoded + 1</font> and store the result in <font face='courier'>hamlet_1_decoded</font>.<br>\n",
        "    <br>\n",
        "    Afterfwards, display the first <font face='courier'>649</font> characters of <font face='courier'>hamlet_1_decoded</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "WyIsQEANHWOk",
        "outputId": "70d7b67d-dc2c-4730-e4b9-5498b7b452d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t h e   t r a g e d i e   o f   h a m l e t \n",
            " \n",
            " a c t u s   p r i m u s .   s c o e n a   p r i m a . \n",
            " \n",
            " e n t e r   b a r n a r d o   a n d   f r a n c i s c o   t w o   c e n t i n e l s . \n",
            " \n",
            "   b a r n a r d o .   w h o ' s   t h e r e ? \n",
            " f r a n .   n a y   a n s w e r   m e :   s t a n d   &   v n f o l d \n",
            " y o u r   s e l f e \n",
            " \n",
            "   b a r .   l o n g   l i u e   t h e   k i n g \n",
            " \n",
            "   f r a n .   b a r n a r d o ? \n",
            " b a r .   h e \n",
            " \n",
            "   f r a n .   y o u   c o m e   m o s t   c a r e f u l l y   v p o n   y o u r   h o u r e \n",
            " \n",
            "   b a r .   ' t i s   n o w   s t r o o k   t w e l u e ,   g e t   t h e e   t o   b e d   f r a n c i s c o\n"
          ]
        }
      ],
      "source": [
        "s1 = hamlet_1_encoded + 1\n",
        "hamlet_1_decoded = ''.join(tokenizer.sequences_to_texts([s1]))\n",
        "print(hamlet_1_decoded[:649])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9R-UmlVHWOl"
      },
      "source": [
        "**Checkpoint:** Your output should look like this:\n",
        "\n",
        "```\n",
        "t h e   t r a g e d i e   o f   h a m l e t\n",
        "\n",
        " a c t u s   p r i m u s .   s c o e n a   p r i m a .\n",
        "\n",
        " e n t e r   b a r n a r d o   a n d   f r a n c i s c o   t w o   c e n t i n e l s .\n",
        "\n",
        "   b a r n a r d o .   w h o ' s   t h e r e ?\n",
        " f r a n .   n a y   a n s w e r   m e :   s t a n d   &   v n f o l d\n",
        " y o u r   s e l f e\n",
        "\n",
        "   b a r .   l o n g   l i u e   t h e   k i n g\n",
        "\n",
        "   f r a n .   b a r n a r d o ?\n",
        " b a r .   h e\n",
        "\n",
        "   f r a n .   y o u   c o m e   m o s t   c a r e f u l l y   v p o n   y o u r   h o u r e\n",
        "\n",
        "   b a r .   ' t i s   n o w   s t r o o k   t w e l u e ,   g e t   t h e e   t o   b e d   f r a n c i s c o\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxBIDOI6HWOl"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Create three objects <font face='courier'>hamlet_1_dataset</font>, <font face='courier'>hamlet_2_dataset</font> and <font face='courier'>hamlet_3_dataset</font> of type <font face='courier'>tf.data.dataset</font> by applying the method<br>\n",
        "    <br>\n",
        "    <font face='courier'>tf.data.Dataset.from_tensor_slices</font> (see <a href='https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices'>this link</a>) to <font face='courier'>hamlet_1_encoded</font>, <font face='courier'>hamlet_2_encoded</font> and <font face='courier'>hamlet_3_encoded</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i1_vyzDHWOm"
      },
      "outputs": [],
      "source": [
        "hamlet_1_dataset = tf.data.Dataset.from_tensor_slices(hamlet_1_encoded)\n",
        "hamlet_2_dataset = tf.data.Dataset.from_tensor_slices(hamlet_2_encoded)\n",
        "hamlet_3_dataset = tf.data.Dataset.from_tensor_slices(hamlet_3_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1T48_CGHWOm"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Display the first ten elements of <font face='courier'>hamlet_1_dataset</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Zs49xjT8HWOn",
        "outputId": "e8aee500-e295-4f5b-a377-a49a6460e27f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(20, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(13, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for i in hamlet_1_dataset.take(10):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwCGYiyxHWOo"
      },
      "source": [
        "**Checkpoint:** You should have produced the following output:\n",
        "\n",
        "```\n",
        "tf.Tensor(2, shape=(), dtype=int32)\n",
        "tf.Tensor(5, shape=(), dtype=int32)\n",
        "tf.Tensor(1, shape=(), dtype=int32)\n",
        "tf.Tensor(0, shape=(), dtype=int32)\n",
        "tf.Tensor(2, shape=(), dtype=int32)\n",
        "tf.Tensor(9, shape=(), dtype=int32)\n",
        "tf.Tensor(4, shape=(), dtype=int32)\n",
        "tf.Tensor(20, shape=(), dtype=int32)\n",
        "tf.Tensor(1, shape=(), dtype=int32)\n",
        "tf.Tensor(13, shape=(), dtype=int32)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW4HjUE_HWOp"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    As you can see, each item of <font face='courier'>hamlet_1_dataset</font> is an integer tensor including one single value.<br>\n",
        "    <br>\n",
        "    Accordingly, <font face='courier'>hamlet_1_dataset</font> has <font face='courier'>len(hamlet_1_encoded)</font> elements in total (the same applies in case of the other two datasets).<br>\n",
        "    <br>\n",
        "    In the following, you will train a recurrent neural network which gets a coded string of length <font face='courier'>T = 100</font> and predicts subsequent characters in all time steps.<br>\n",
        "    <br>\n",
        "    Accordingly, we will first transform our three datasets such that their elements become one-dimensional tensors of length <font face='courier'>window_length = T + 1</font>.<br>\n",
        "    <br>\n",
        "    Initialize <font face='courier'>T</font> and <font face='courier'>window_length</font> as described.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RZdF-npHWOp"
      },
      "outputs": [],
      "source": [
        "T = 100\n",
        "window_length = T + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v08JuCC5HWOp"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Use the method <font face='courier'>tf.data.Dataset.window</font> (see <a href='https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window'>this link</a>) to get items that feature the desired length.<br>\n",
        "    <br>\n",
        "    Call the method using the arguments <font face='courier'>shift = 1</font> and <font face='courier'>drop_remainder = True</font>.<br>\n",
        "    <br>\n",
        "    The first-mentioned argument <font face='courier'>shift = 1</font> ensures that the first item of the transformed dataset contains the elements <font face='courier'>0,...,window_length - 1</font> of the original dataset, the next item <font face='courier'>1,...,window_length</font>, and so on.<br>\n",
        "    <br>\n",
        "    In other words: A window of length <font face='courier'>window_length</font> slides with feed <font face='courier'>shift</font> over the original dataset and extracts sequence by sequence until the end of the dataset is reached.<br>\n",
        "    <br>\n",
        "    The latter argument <font face='courier'>drop_remainder = True</font> ensures that no shorter sequences are extracted towards the end of the dataset, where the window could potentially slide beyond the end of the dataset.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr4IDGXnHWOp"
      },
      "outputs": [],
      "source": [
        "hamlet_1_dataset= hamlet_1_dataset.window(size= window_length, shift= 1, drop_remainder=True)\n",
        "hamlet_2_dataset= hamlet_2_dataset.window(size= window_length, shift= 1, drop_remainder=True)\n",
        "hamlet_3_dataset= hamlet_3_dataset.window(size= window_length, shift= 1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7AdohjyHWOp"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Execute the following code.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "63EfUWWOHWOq",
        "outputId": "1841212f-6312-4b06-9dd9-bbee2a55c877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(20, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(13, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for window in hamlet_1_dataset.take(1):\n",
        "    print(window)\n",
        "    for item in window.take(10):\n",
        "        print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rEXa3M8HWOq"
      },
      "source": [
        "**Checkpoint:** You should have obtained an output like this:\n",
        "\n",
        "```\n",
        "<_VariantDataset shapes: (), types: tf.int32>\n",
        "tf.Tensor(2, shape=(), dtype=int32)\n",
        "tf.Tensor(5, shape=(), dtype=int32)\n",
        "tf.Tensor(1, shape=(), dtype=int32)\n",
        "tf.Tensor(0, shape=(), dtype=int32)\n",
        "tf.Tensor(2, shape=(), dtype=int32)\n",
        "tf.Tensor(9, shape=(), dtype=int32)\n",
        "tf.Tensor(4, shape=(), dtype=int32)\n",
        "tf.Tensor(20, shape=(), dtype=int32)\n",
        "tf.Tensor(1, shape=(), dtype=int32)\n",
        "tf.Tensor(13, shape=(), dtype=int32)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRJkxG79HWOr"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    As you can see, the transformed datasets <font face='courier'>hamlet_1_dataset</font>, <font face='courier'>hamlet_2_dataset</font> and <font face='courier'>hamlet_3_dataset</font> have now elements which are again objects of type <font face='courier'>tf.data.Dataset</font> (or of a derived class).<br>\n",
        "    <br>\n",
        "    Each of these sub-datasets <font face='courier'>window</font> contains a number of <font face='courier'>window_size</font> single-valued tensors.<br>\n",
        "    <br>\n",
        "    Apply the method <font face='courier'>tf.data.Dataset.flat_map</font> (see <a href='https://www.tensorflow.org/api_docs/python/tf/data/Dataset#flat_map'>this link</a>) to all three datasets to transform the sub-datasets <font face='courier'>window</font> into one-dimensional tensors of length <font face='courier'>window_length</font>.<br>\n",
        "    <br>\n",
        "    Pass a function which maps <font face='courier'>window</font> to <font face='courier'>window.batch(window_length)</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSsCFHUaHWOr"
      },
      "outputs": [],
      "source": [
        "hamlet_1_dataset= hamlet_1_dataset.flat_map(lambda window:window.batch(window_length))\n",
        "hamlet_2_dataset= hamlet_2_dataset.flat_map(lambda window:window.batch(window_length))\n",
        "hamlet_3_dataset= hamlet_3_dataset.flat_map(lambda window:window.batch(window_length))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc-mkN59HWOr"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Display the first element of <font face='courier'>hamlet_1_dataset</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KEs7BaaHWOs",
        "outputId": "2974fd92-b5a2-4e76-ae2e-eb2b8801434b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[ 2  5  1  0  2  9  4 20  1 13  6  1  0  3 18  0  5  4 14 10  1  2 11 11\n",
            "  4 19  2 12  8  0 22  9  6 14 12  8 21  0  8 19  3  1  7  4  0 22  9  6\n",
            " 14  4 21 11 11  1  7  2  1  9  0 23  4  9  7  4  9 13  3  0  4  7 13  0\n",
            " 18  9  4  7 19  6  8 19  3  0  2 17  3  0 19  1  7  2  6  7  1 10  8 21\n",
            " 11 11  0 23  4], shape=(101,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for i in hamlet_1_dataset.take(1):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2e5GcOnHWOs"
      },
      "source": [
        "**Checkpoint:** You should get the following output:\n",
        "\n",
        "```\n",
        "tf.Tensor(\n",
        "[ 2  5  1  0  2  9  4 20  1 13  6  1  0  3 18  0  5  4 14 10  1  2 11 11\n",
        "  4 19  2 12  8  0 22  9  6 14 12  8 21  0  8 19  3  1  7  4  0 22  9  6\n",
        " 14  4 21 11 11  1  7  2  1  9  0 23  4  9  7  4  9 13  3  0  4  7 13  0\n",
        " 18  9  4  7 19  6  8 19  3  0  2 17  3  0 19  1  7  2  6  7  1 10  8 21\n",
        " 11 11  0 23  4], shape=(101,), dtype=int32)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl0TpPbBHWOs"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Apply the method <font face='courier'>tf.data.Dataset.concatenate</font> (see <a href='https://www.tensorflow.org/api_docs/python/tf/data/Dataset#concatenate'>this link</a>) to merge<br>\n",
        "    <br>\n",
        "    <font face='courier'>hamlet_1_dataset</font>, <font face='courier'>hamlet_2_dataset</font> and <font face='courier'>hamlet_3_dataset</font> to a single dataset <font face='courier'>hamlet_dataset</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoMS-NoaHWOs"
      },
      "outputs": [],
      "source": [
        "hamlet_dataset= (hamlet_1_dataset.concatenate(hamlet_2_dataset)).concatenate(hamlet_3_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK_KciGuHWOt"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Set <font face='courier'>batch_size = 32</font>.<br>\n",
        "    <br>\n",
        "    Apply <font face='courier'>tf.data.Dataset.repeat</font> (without argument),<br>\n",
        "    <br>\n",
        "    <font face='courier'>tf.data.Dataset.shuffle</font> (with <font face='courier'>buffer_size = 1000</font>)<br>\n",
        "    <br>\n",
        "    and finally <font face='courier'>tf.data.Dataset.batch</font> (with <font face='courier'>drop_remainder=True</font>).\n",
        "    <a href=''></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL-JhVH6HWOt"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "batch_size= 32\n",
        "hamlet_dataset= hamlet_dataset.repeat().shuffle(buffer_size= 10000).batch(batch_size, drop_remainder= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiWZYyDmHWOt"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Our dataset contains now two-dimensional tensors <font face='courier'>window_batch</font> of size <font face='courier'>(32, 101)</font>.<br>\n",
        "    <br>\n",
        "    Each slice <font face='courier'>window_batch[i, :]</font> corresponds to a training example.<br>\n",
        "    <br>\n",
        "    Here, we still need to subdivide the training examples into inputs and outputs.<br>\n",
        "    <br>\n",
        "    Each single encoded character <font face='courier'>window_batch[i, j]</font> (for <font face='courier'>j=0,...,99</font>) is an  input $\\mathbf{x}^{<t>(i)}$ in a time step<br>\n",
        "    <br>\n",
        "    and the associated output is <font face='courier'>window_batch[i, j + 1]</font> which corresponds to $\\mathbf{y}^{<t>(i)}$.<br>\n",
        "    <br>\n",
        "    Apply the method <font face='courier'>tf.data.Dataset.map</font> (see <a href='https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map'>this link</a>) to <font face='courier'>hamlet_dataset</font><br>.\n",
        "    <br>\n",
        "    Each batch <font face='courier'>window_batch</font> shall be mapped to a tuple of two tensors of size <font face='courier'>(32, 100)</font>.<br>\n",
        "    <br>\n",
        "    The <font face='courier'>[i, :]</font>-th slice of the first tensor shall contain the entries <font face='courier'>window_batch[i, 0:100]</font>.<br>\n",
        "    <br>\n",
        "    The corresponding slice of the second tensor shall contain <font face='courier'>window_batch[i, 1:101]</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWMtpumUHWOt"
      },
      "outputs": [],
      "source": [
        "hamlet_dataset = hamlet_dataset.map(lambda window_batch: (window_batch[:, 0:100], window_batch[:, 1:101]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH-tJDbgHWOu"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Execute the following code.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdiH2uKGHWOu",
        "outputId": "487d19d3-a27b-40d5-acae-b938d81cdb18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  o f   y o u n g   f o r t i n b r a s , \n",
            " w h o   i m p o t e n t   a n d   b e d r i d ,   s c a r s e l y   h e a r e s \n",
            " o f   t h i s   h i s   n e p h e w e s   p u r p o s e ,   t o   s u p p\n",
            "\n",
            "o f   y o u n g   f o r t i n b r a s , \n",
            " w h o   i m p o t e n t   a n d   b e d r i d ,   s c a r s e l y   h e a r e s \n",
            " o f   t h i s   h i s   n e p h e w e s   p u r p o s e ,   t o   s u p p r\n"
          ]
        }
      ],
      "source": [
        "for window_batch in hamlet_dataset.take(1):\n",
        "    [x] = tokenizer.sequences_to_texts([window_batch[0][0, :].numpy() + 1])\n",
        "    [y] = tokenizer.sequences_to_texts([window_batch[1][0, :].numpy() + 1])\n",
        "    print(x)\n",
        "    print()\n",
        "    print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhMICr73HWOu"
      },
      "source": [
        "**Checkpoint:** Your output should look as follows:\n",
        "\n",
        "```\n",
        "  o f   y o u n g   f o r t i n b r a s ,\n",
        " w h o   i m p o t e n t   a n d   b e d r i d ,   s c a r s e l y   h e a r e s\n",
        " o f   t h i s   h i s   n e p h e w e s   p u r p o s e ,   t o   s u p p\n",
        "\n",
        "o f   y o u n g   f o r t i n b r a s ,\n",
        " w h o   i m p o t e n t   a n d   b e d r i d ,   s c a r s e l y   h e a r e s\n",
        " o f   t h i s   h i s   n e p h e w e s   p u r p o s e ,   t o   s u p p r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp0KUnrSHWOu"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Apply <font face='courier'>tf.data.Dataset.map</font> again to <font face='courier'>hamlet_dataset</font> to map each element <font face='courier'>(X_batch, Y_batch)</font> to a new tuple.<br>\n",
        "    <br>\n",
        "    In the new tuple, <font face='courier'>Y_batch</font> shall remain unchanged while <font face='courier'>X_batch</font> undergoes another encoding via <font face='courier'>tf.one_hot</font> (see <a href='https://www.tensorflow.org/api_docs/python/tf/one_hot'>this link</a>).<br>\n",
        "    <br>\n",
        "    Find out, which value <font face='courier'>depth</font> you need to pass <font face='courier'>tf.one_hot</font> in addition to <font face='courier'>X_batch</font>.<br>\n",
        "    <br>\n",
        "    Hint: You already computed the correct value above.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-7Muz8eHWOv"
      },
      "outputs": [],
      "source": [
        "hamlet_dataset= hamlet_dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F60WUmSpHWOv"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Apply the method <font face='courier'>tf.data.Dataset.prefetch</font> (with <font face='courier'>buffer_size = 1</font>) to <font face='courier'>hamlet_dataset</font> to get your dataset ready for training.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3HTJuE4HWOv"
      },
      "outputs": [],
      "source": [
        "hamlet_dataset = hamlet_dataset.prefetch(buffer_size= 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loUQtSaRHWOv"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Deduce a formula for the number of elements in <font face='courier'>hamlet_dataset</font>.<br>\n",
        "    <br>\n",
        "    Display the result and store it in <font face='courier'>steps_per_epoch</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNRKyS6tHWOw",
        "outputId": "79d3453c-71e5-41f2-e34c-b93a46ae1e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5014\n"
          ]
        }
      ],
      "source": [
        "steps = ((len(hamlet_1_encoded)+len(hamlet_2_encoded)+len(hamlet_3_encoded))-3*T)\n",
        "steps_per_epoch = int(steps/batch_size)\n",
        "print(steps_per_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opiVFH_jHWOw"
      },
      "source": [
        "**Checkpoint:** The number of items in the dataset should be as follows:\n",
        "\n",
        "```\n",
        "5014\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OelaY1vMHWOw"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Use <font face='courier'>keras.models.Sequential</font> to define a <font face='courier'>model</font> featuring<br>\n",
        "    <br>\n",
        "    two hidden GRU layers (see <a href='https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU'>this link</a>) with <font face='courier'>128</font> neurons each, as well as<br>\n",
        "    <br>\n",
        "    a fully connected output layer (see <a href='https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense'>this link</a>) with <font face='courier'>max_id</font> neurons and <font face='courier'>softmax</font> activation function.<br>\n",
        "    <br>\n",
        "    This model corresponds to the RNN displayed in Fig. 1 with an additional hidden GRU layer.<br>\n",
        "    <br>\n",
        "    To make the model generate outputs in each time step, the output layer must be enclosed by a <font face='courier'>keras.layers.TimeDistributed</font> wrapper (see <a href='https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed'>this link</a>).<br>\n",
        "    <br>\n",
        "    Without the layer, the model would generate only a single output in the very last time step (as the one displaye in Fig. 2).<br>\n",
        "    <br>\n",
        "    In case of the GRU layers, you should add <font face='courier'>return_sequences = True</font> for the same purpose.<br>\n",
        "    <br>\n",
        "    Also recall that the input layer needs an argument <font face='courier'>input_shape=[None, max_id]</font> (where <font face='courier'>None</font> represents the temporal dimension of the input sequence).<br>\n",
        "    <br>\n",
        "    During training, we could just as well replace <font face='courier'>None</font> with <font face='courier'>T</font> as all sequences in the training data have identical length.<br>\n",
        "    <br>\n",
        "    However, passing <font face='courier'>None</font> ensures that the model will accept arbitrarily long sequences later.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1n_X6MaHWOx"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add((keras.layers.GRU(128,return_sequences=True, input_shape=[None,max_id])))\n",
        "model.add(keras.layers.GRU(128,return_sequences=True))\n",
        "model.add(keras.layers.TimeDistributed(keras.layers.Dense(max_id,activation=\"softmax\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4KnAUZlHWOx"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Compile <font face='courier'>model</font> using <font face='courier'>sparse_categorical_crossentropy</font> and <font face='courier'>adam</font>.\n",
        "    <a href=''></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xGyGBGAHWOx"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTlQGUr9HWOx"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Train <font face='courier'>model</font> for one epoch. Don't forget to pass the <font face='courier'>steps_per_epoch</font> argument.\n",
        "    <a href=''></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "X-rLLplSHWOy",
        "outputId": "d10bfb63-eedd-491f-d155-6f32139e988d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3165/5014 [=================>............] - ETA: 35:21 - loss: 1.3261"
          ]
        }
      ],
      "source": [
        "model.fit(hamlet_dataset, epochs=1, steps_per_epoch= steps_per_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuMRMU5WHWOy"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    You might have observed that even a single epoch takes quite some time.<br>\n",
        "    <br>\n",
        "    Create a file <font face='courier'>hamlet_rnn.py</font> and train the model for <font face='courier'>20</font> epochs on the GPU cluster.<br>\n",
        "    <br>\n",
        "    In doing so, use a callback<br>\n",
        "    <br>\n",
        "    <font face='courier'>keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)</font><br>\n",
        "    <br>\n",
        "    (see <a href='https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping'>this link</a>). Save your model as  <font face='courier'>hamlet_model.h5</font> and load it in the following step for further use in this notebook.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fERuGZICHWOy"
      },
      "outputs": [],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFKoBghGHWOz"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Write a function <font face='courier'>preprocess</font> that takes a argument a list <font face='courier'>texts</font> containing a single string.<br>\n",
        "    <br>\n",
        "    Inside this function, use <font face='courier'>tokenizer</font> again to encode the string in <font face='courier'>texts</font> as a NumPy-Array <font face='courier'>X</font>.<br>\n",
        "    <br>\n",
        "    The return value of <font face='courier'>preprocess</font> shall be the one-hot encoded version of <font face='courier'>X</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBjmSVo7HWOz"
      },
      "outputs": [],
      "source": [
        "def preprocess(texts):\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yvZ35utHWOz"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    The function <font face='courier'>next_char</font> takes as argument a string <font face='courier'>text</font> and a positive number <font face='courier'>temperature</font><br>\n",
        "    <br>\n",
        "    with the goal to generate the next character after <font face='courier'>text</font>.<br>\n",
        "    <br>\n",
        "    Replace all placeholders <font face='courier'>None</font> as follows:<br>\n",
        "    <br>\n",
        "    First, apply <font face='courier'>preprocess</font> to encode <font face='courier'>text</font> and store the result in <font face='courier'>X_new</font>.<br>\n",
        "    <br>\n",
        "    Second, apply <font face='courier'>model.predict</font> the generate outputs given the input sequence <font face='courier'>X_new</font>.<br>\n",
        "    <br>\n",
        "    Store the output from the last time step in <font face='courier'>y_proba</font>.<br>\n",
        "    <br>\n",
        "    <font face='courier'>rescaled_logits</font> and <font face='courier'>char_id</font> are finally used to generate a one-element sample from  $\\{1,\\dots,\\mathrm{max\\_id}\\}$.<br>\n",
        "    <br>\n",
        "    The generated sample is the encoded version of the character to be generated.<br>\n",
        "    <br>\n",
        "    Hence, <font face='courier'>char_id.numpy()</font> will return the character itself.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJCl8SpBHWOz"
      },
      "outputs": [],
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = None\n",
        "    y_proba = None\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ClVWP5VHWOz"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    The function <font face='courier'>complete_text</font> takes a string <font face='courier'>text</font> and shall append <font face='courier'>n_char</font> subsequent characters generated by your RNN.<br>\n",
        "    <br>\n",
        "    Complete the function accordingly. The argument <font face='courier'>temperature</font> just needs to be passed to <font face='courier'>next_char</font>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkPYtxClHWO0"
      },
      "outputs": [],
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += None\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPigu9hhHWO0"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    Starting from the initial string <font face='courier'>'Hamlet'</font>, use <font face='courier'>complete_text</font> to generate a text with <font face='courier'>1000</font> characters.<br>\n",
        "    <br>\n",
        "    You can vary the argument <font face='courier'>temperature</font> to modify the distribution from which new characters are drawn.<br>\n",
        "    <br>\n",
        "    Values close to zero encourage characters that have a high probability according to the distribution generated by your RNN.<br>\n",
        "    <br>\n",
        "    If <font face='courier'>temperature</font> is too high, new characters are drawn according to a uniform distribution on the entire vocabulary, which is not desirable.<br>\n",
        "    <br>\n",
        "    You can, for example, try different values between <font face='courier'>0</font> and <font face='courier'>2</font> and evaluate generated texts based on how plausible they appear to you.<br>\n",
        "    <br>\n",
        "    Display your generated text.\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}